import os
import zipfile
import tempfile
import shutil
import json
from datetime import datetime
from pathlib import Path
from collections import defaultdict

import streamlit as st
import pandas as pd
import plotly.express as px

from analyzer.github_fetcher import download_repo_zip, unzip_to_folder
from analyzer.extractor import extract_uploaded_zip
from analyzer.metrics import analyze_project
from analyzer.scoring import compute_scores
from analyzer.report import save_json_report

# ----------------------------
# Configura√ß√£o inicial
# ----------------------------
st.set_page_config(page_title="E-commerce Architecture Compare", layout="wide")

st.title("‚öñÔ∏è Comparador Arquitetural: DDD vs N√£o-DDD (E-commerce)")

# ----------------------------
# Sidebar de entrada
# ----------------------------
with st.sidebar:
    st.header("üì• Entrada")
    input_mode = st.radio("Como fornecer c√≥digo?", ["GitHub URL", "Upload ZIP"])
    token = st.text_input("GitHub token (opcional, para reposit√≥rios privados/limite API)", type="password")
    if input_mode == "GitHub URL":
        repo_a = st.text_input("Repo 1 (URL ou owner/repo)")
        repo_b = st.text_input("Repo 2 (URL ou owner/repo)")
    else:
        up_a = st.file_uploader("Zip do projeto 1", type=['zip'])
        up_b = st.file_uploader("Zip do projeto 2", type=['zip'])

    st.write("---")
    st.header("‚öñÔ∏è Pesos (opcional)")
    w_man = st.slider("Peso - Manutenibilidade", 0.0, 1.0, 0.35)
    w_comp = st.slider("Peso - Complexidade", 0.0, 1.0, 0.25)
    w_cpl = st.slider("Peso - Acoplamento", 0.0, 1.0, 0.20)
    w_struct = st.slider("Peso - Estrutura/Dom√≠nio", 0.0, 1.0, 0.20)
    if abs((w_man + w_comp + w_cpl + w_struct) - 1.0) > 0.01:
        st.warning("Os pesos devem somar aproximadamente 1.0. Ajustarei automaticamente na execu√ß√£o.")

run = st.button("‚ñ∂Ô∏è Rodar an√°lise")

# ----------------------------
# Fun√ß√£o de exibi√ß√£o do relat√≥rio
# ----------------------------
def show_report(metrics_a, metrics_b, scores_a, scores_b, name_a, name_b):
    st.subheader("üìä Resumo Executivo")
    col1, col2 = st.columns(2)

    with col1:
        st.metric("Projeto 1", name_a)
        st.metric("Linhas de C√≥digo (LOC)", metrics_a['loc'])
        st.metric("Arquivos Python", metrics_a['num_py_files'])
        st.metric("Complexidade M√©dia (CC)", f"{metrics_a['complexity']['avg_cc']:.2f}")
        st.metric("√çndice de Manutenibilidade (MI)", f"{metrics_a['complexity']['avg_mi']:.2f}")
        st.metric("Acoplamento", metrics_a['coupling']['total_import_links'])
        st.metric("Dom√≠nios Detectados", metrics_a['domain']['domain_segments'])
        st.metric("Score Final", f"{scores_a['final_score']:.2f}")

    with col2:
        st.metric("Projeto 2", name_b)
        st.metric("Linhas de C√≥digo (LOC)", metrics_b['loc'])
        st.metric("Arquivos Python", metrics_b['num_py_files'])
        st.metric("Complexidade M√©dia (CC)", f"{metrics_b['complexity']['avg_cc']:.2f}")
        st.metric("√çndice de Manutenibilidade (MI)", f"{metrics_b['complexity']['avg_mi']:.2f}")
        st.metric("Acoplamento", metrics_b['coupling']['total_import_links'])
        st.metric("Dom√≠nios Detectados", metrics_b['domain']['domain_segments'])
        st.metric("Score Final", f"{scores_b['final_score']:.2f}")

    st.write("---")

    # Compara√ß√£o em tabela
    st.subheader("üìë Tabela Comparativa")
    df = pd.DataFrame([
        {
            'Projeto': name_a,
            'LOC': metrics_a['loc'],
            'Arquivos Python': metrics_a['num_py_files'],
            'Complexidade M√©dia (CC)': metrics_a['complexity']['avg_cc'],
            '√çndice MI': metrics_a['complexity']['avg_mi'],
            'Acoplamento': metrics_a['coupling']['total_import_links'],
            'Dom√≠nios Detectados': metrics_a['domain']['domain_segments'],
            'Score Final': scores_a['final_score']
        },
        {
            'Projeto': name_b,
            'LOC': metrics_b['loc'],
            'Arquivos Python': metrics_b['num_py_files'],
            'Complexidade M√©dia (CC)': metrics_b['complexity']['avg_cc'],
            '√çndice MI': metrics_b['complexity']['avg_mi'],
            'Acoplamento': metrics_b['coupling']['total_import_links'],
            'Dom√≠nios Detectados': metrics_b['domain']['domain_segments'],
            'Score Final': scores_b['final_score']
        }
    ])
    st.dataframe(df, use_container_width=True)

    st.write("---")

    # Radar chart
    st.subheader("üìà Compara√ß√£o Visual por M√©trica (Radar)")
    categories = ['manutenibilidade','complexidade','coupling','structure']
    radar_a = [scores_a['manutenibilidade'], scores_a['complexidade'], scores_a['coupling'], scores_a['structure']]
    radar_b = [scores_b['manutenibilidade'], scores_b['complexidade'], scores_b['coupling'], scores_b['structure']]
    radar_df = pd.DataFrame({
        'M√©trica': categories + categories,
        'Valor': radar_a + radar_b,
        'Projeto': [name_a]*len(categories) + [name_b]*len(categories)
    })
    fig = px.line_polar(radar_df, r='Valor', theta='M√©trica', color='Projeto', line_close=True)
    st.plotly_chart(fig, use_container_width=True)

    st.write("---")

    # Conclus√£o autom√°tica
    st.subheader("üìù An√°lise Autom√°tica")
    if scores_a['final_score'] > scores_b['final_score']:
        st.success(f"‚úÖ O projeto **{name_a}** apresentou melhor score geral, indicando maior qualidade arquitetural.")
    elif scores_b['final_score'] > scores_a['final_score']:
        st.success(f"‚úÖ O projeto **{name_b}** apresentou melhor score geral, indicando maior qualidade arquitetural.")
    else:
        st.warning("‚öñÔ∏è Ambos os projetos tiveram scores equivalentes ‚Äî recomenda-se inspe√ß√£o qualitativa.")

    st.info("‚ÑπÔ∏è Observa√ß√£o: m√©tricas autom√°ticas s√£o apoio; recomenda-se avalia√ß√£o qualitativa especialmente em **separa√ß√£o de dom√≠nio e coes√£o**.")

# ----------------------------
# Execu√ß√£o principal
# ----------------------------
if run:
    tmproot = tempfile.mkdtemp()
    proj_paths = []
    names = []
    try:
        for idx in [1,2]:
            st.info(f"Processando projeto {idx}...")
            if input_mode == "GitHub URL":
                url = repo_a if idx==1 else repo_b
                if not url:
                    st.error("Informe as duas URLs antes de rodar.")
                    raise SystemExit()
                zip_path = download_repo_zip(url, dest_folder=tmproot, token=token if token else None)
                base = unzip_to_folder(zip_path, None)
            else:
                up = up_a if idx==1 else up_b
                if up is None:
                    st.error("Fa√ßa upload dos dois zips antes de rodar.")
                    raise SystemExit()
                tmpf = os.path.join(tmproot, f"proj{idx}.zip")
                with open(tmpf, 'wb') as fh:
                    fh.write(up.read())
                base = extract_uploaded_zip(tmpf)

            st.success(f"Projeto {idx} extra√≠do em {base}")
            proj_paths.append(base)
            names.append(os.path.basename(base))

        st.info("Extraindo m√©tricas...")
        metrics = [analyze_project(p) for p in proj_paths]

        W = {'manutenibilidade': w_man, 'complexidade': w_comp, 'coupling': w_cpl, 'structure': w_struct}
        s = sum(W.values())
        W = {k: (v/s) for k,v in W.items()}  # normaliza pesos

        scores_a, scores_b = compute_scores(metrics[0], metrics[1], weights=W)

        # Exibir relat√≥rio novo
        show_report(metrics[0], metrics[1], scores_a, scores_b, names[0], names[1])

        # Salvar JSON
        out_json = os.path.join(tmproot, 'report.json')
        payload = {'metrics': [metrics[0], metrics[1]], 'scores': [scores_a, scores_b], 'names': names}
        save_json_report(out_json, payload)
        st.success(f"üìÇ Relat√≥rio JSON salvo em {out_json}")

    except Exception as e:
        st.error(f"‚ùå Erro na execu√ß√£o: {e}")
    finally:
        st.info("‚úÖ Execu√ß√£o finalizada. Lembre de remover arquivos tempor√°rios se quiser.")
