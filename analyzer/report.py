import streamlit as st
import pandas as pd
import plotly.express as px
import json
from pathlib import Path

# --- MUDAN√áA AQUI ---
# A fun√ß√£o agora aceita 'weights' (pesos) vindos do app.py
def show_report(metrics_a, metrics_b, scores_a, scores_b, name_a, name_b, weights):
# --- FIM DA MUDAN√áA ---

    st.title("üìä Relat√≥rio Comparativo de M√©tricas Arquiteturais")
    st.write(f"An√°lise visual e quantitativa entre **{name_a}** e **{name_b}**.") # T√≠tulo atualizado

    # Tenta acessar as chaves com seguran√ßa
    try:
        # === Dados base ===
        df_summary = pd.DataFrame([
            {
                'Projeto': name_a,
                'LOC': metrics_a['loc'],
                'Arquivos Python': metrics_a['num_py_files'],
                'Complexidade M√©dia (CC)': metrics_a['complexity']['avg_cc'],
                '√çndice MI': metrics_a['complexity']['avg_mi'],
                'Acoplamento': metrics_a['coupling']['total_import_links'],
                'Dom√≠nios Detectados': metrics_a['domain']['domain_segments'],
                'Classes': metrics_a['ast']['classes'],
                'Fun√ß√µes': metrics_a['ast']['functions'],
                'Score Final': scores_a['final_score']
            },
            {
                'Projeto': name_b,
                'LOC': metrics_b['loc'],
                'Arquivos Python': metrics_b['num_py_files'],
                'Complexidade M√©dia (CC)': metrics_b['complexity']['avg_cc'],
                '√çndice MI': metrics_b['complexity']['avg_mi'],
                'Acoplamento': metrics_b['coupling']['total_import_links'],
                'Dom√≠nios Detectados': metrics_b['domain']['domain_segments'],
                'Classes': metrics_b['ast']['classes'],
                'Fun√ß√µes': metrics_b['ast']['functions'],
                'Score Final': scores_b['final_score']
            }
        ])
        
        # Pega os valores para facilitar a compara√ß√£o
        # val_a √© "Projeto DDD", val_b √© "Projeto Tradicional"
        val_a = df_summary.iloc[0]
        val_b = df_summary.iloc[1]

    except KeyError as e:
        st.error(f"‚ùå Erro ao processar os dados: a chave {e} est√° faltando nas m√©tricas.")
        st.write("Verifique a sa√≠da da fun√ß√£o `analyze_project`.")
        return

    # === Gr√°ficos por m√©trica ===
    st.subheader("üìè Linhas de C√≥digo (LOC)")
    fig_loc = px.bar(df_summary, x='LOC', y='Projeto', orientation='h', color='Projeto',
                     title='Comparativo de Linhas de C√≥digo (LOC)')
    st.plotly_chart(fig_loc, use_container_width=True)
    st.markdown(f"üí° **Observa√ß√£o:** O **{name_a}** possui **{val_a['LOC']}** linhas de c√≥digo, enquanto **{name_b}** possui **{val_b['LOC']}**.")
    st.markdown("*(LOC √© uma m√©trica de tamanho; 'melhor' depende do contexto. Projetos DDD podem ser maiores devido √† separa√ß√£o expl√≠cita de camadas.)*")


    st.subheader("‚öôÔ∏è Complexidade Ciclom√°tica M√©dia (CC)")
    fig_cc = px.bar(df_summary, x='Projeto', y='Complexidade M√©dia (CC)', color='Projeto',
                    title='Complexidade Ciclom√°tica M√©dia por Projeto')
    st.plotly_chart(fig_cc, use_container_width=True)
    if val_a['Complexidade M√©dia (CC)'] < val_b['Complexidade M√©dia (CC)']:
        st.info(f"üí° **An√°lise (Complexidade):** O **{name_a}** vence, com **menor** complexidade m√©dia ({val_a['Complexidade M√©dia (CC)']:.2f}) que {name_b} ({val_b['Complexidade M√©dia (CC)']:.2f}). Menor complexidade √© geralmente melhor.")
    else:
        st.info(f"üí° **An√°lise (Complexidade):** O **{name_b}** vence, com **menor** complexidade m√©dia ({val_b['Complexidade M√©dia (CC)']:.2f}) que {name_a} ({val_a['Complexidade M√©dia (CC)']:.2f}). Menor complexidade √© geralmente melhor.")

    st.subheader("üß† √çndice de Manutenibilidade (MI)")
    fig_mi = px.bar(df_summary, x='Projeto', y='√çndice MI', color='Projeto',
                    title='√çndice de Manutenibilidade (MI)')
    st.plotly_chart(fig_mi, use_container_width=True)
    if val_a['√çndice MI'] > val_b['√çndice MI']:
        st.info(f"üí° **An√°lise (Manutenibilidade):** O **{name_a}** vence, com **maior** √≠ndice ({val_a['√çndice MI']:.2f}) que {name_b} ({val_b['√çndice MI']:.2f}). Scores mais altos indicam c√≥digo mais f√°cil de manter.")
    else:
        st.info(f"üí° **An√°lise (Manutenibilidade):** O **{name_b}** vence, com **maior** √≠ndice ({val_b['√çndice MI']:.2f}) que {name_a} ({val_a['√çndice MI']:.2f}). Scores mais altos indicam c√≥digo mais f√°cil de manter.")


    st.subheader("üîó Acoplamento entre M√≥dulos")
    fig_cpl = px.bar(df_summary, x='Projeto', y='Acoplamento', color='Projeto',
                     title='N√≠vel de Acoplamento entre Componentes Internos')
    st.plotly_chart(fig_cpl, use_container_width=True)
    if val_a['Acoplamento'] < val_b['Acoplamento']:
        st.info(f"üí° **An√°lise (Acoplamento):** O **{name_a}** vence, com **menor** acoplamento ({val_a['Acoplamento']}) que {name_b} ({val_b['Acoplamento']}). Menor acoplamento (menos importa√ß√µes internas) √© crucial para a independ√™ncia dos m√≥dulos.")
    else:
        st.info(f"üí° **An√°lise (Acoplamento):** O **{name_b}** vence, com **menor** acoplamento ({val_b['Acoplamento']}) que {name_a} ({val_a['Acoplamento']}). Menor acoplamento (menos importa√ß√µes internas) √© crucial para a independ√™ncia dos m√≥dulos.")


    st.subheader("üèóÔ∏è Estrutura de Dom√≠nio Detectada")
    fig_dom = px.pie(df_summary, values='Dom√≠nios Detectados', names='Projeto',
                     title='Distribui√ß√£o de Dom√≠nios Detectados')
    st.plotly_chart(fig_dom, use_container_width=True)
    if val_a['Dom√≠nios Detectados'] > val_b['Dom√≠nios Detectados']:
        st.info(f"üí° **An√°lise (Dom√≠nio):** O **{name_a}** parece ter **melhor separa√ß√£o** de dom√≠nio ({val_a['Dom√≠nios Detectados']} segmentos) que {name_b} ({val_b['Dom√≠nios Detectados']}). Isso √© um forte indicador de uma abordagem DDD.")
    else:
        st.info(f"üí° **An√°lise (Dom√≠nio):** O **{name_b}** parece ter **melhor separa√ß√£o** de dom√≠nio ({val_b['Dom√≠nios Detectados']} segmentos) que {name_a} ({val_a['Dom√≠nios Detectados']}).")


    st.subheader("üß© Classes e Fun√ß√µes")
    df_long = df_summary.melt(id_vars='Projeto', value_vars=['Classes', 'Fun√ß√µes'],
                              var_name='Tipo', value_name='Quantidade')
    fig_ast = px.bar(df_long, x='Projeto', y='Quantidade', color='Tipo',
                     barmode='group', title='Distribui√ß√£o de Classes e Fun√ß√µes')
    st.plotly_chart(fig_ast, use_container_width=True)
    st.markdown(f"üí° **Observa√ß√£o:** **{name_a}** possui **{val_a['Classes']}** classes e **{val_a['Fun√ß√µes']}** fun√ß√µes. **{name_b}** possui **{val_b['Classes']}** classes e **{val_b['Fun√ß√µes']}** fun√ß√µes.")


    st.subheader("üåê Score Arquitetural Final")
    fig_score = px.bar(df_summary, x='Score Final', y='Projeto', orientation='h', color='Projeto',
                       title='Pontua√ß√£o Arquitetural Global (0‚Äì100)', text='Score Final')
    fig_score.update_traces(texttemplate='%{text:.1f}', textposition='outside')
    st.plotly_chart(fig_score, use_container_width=True)


    st.subheader("üìà Radar de Compara√ß√£o Geral (Ponderado)")
    categories = ['manutenibilidade', 'complexidade', 'coupling', 'structure']
    
    try:
        # --- MUDAN√áA AQUI ---
        # Multiplica o score (0-100) pelo peso (0-1) para mostrar a *contribui√ß√£o* da m√©trica
        radar_a = [scores_a[m] * weights.get(m, 0) for m in categories]
        radar_b = [scores_b[m] * weights.get(m, 0) for m in categories]
        # --- FIM DA MUDAN√áA ---
        
        radar_df = pd.DataFrame({
            'M√©trica': categories + categories,
            'Valor Ponderado': radar_a + radar_b,
            'Projeto': [name_a]*len(categories) + [name_b]*len(categories)
        })
        
        # --- MUDAN√áA AQUI ---
        # O eixo 'r' agora √© 'Valor Ponderado'
        fig_radar = px.line_polar(radar_df, r='Valor Ponderado', theta='M√©trica', color='Projeto', line_close=True)
        # --- FIM DA MUDAN√áA ---
        
        st.plotly_chart(fig_radar, use_container_width=True)
    except KeyError as e:
        st.error(f"‚ùå Erro ao gerar gr√°fico Radar: a chave {e} est√° faltando nos scores.")
        st.write("Verifique a sa√≠da da fun√ß√£o `compute_scores`.")


    # === Conclus√£o ===
    st.subheader("üßæ An√°lise Autom√°tica (Score Final)")
    winner_name = ""
    loser_name = ""
    if scores_a['final_score'] > scores_b['final_score']:
        winner_name = name_a # Projeto DDD
        loser_name = name_b # Projeto Tradicional
        st.success(f"‚úÖ O **{winner_name}** apresentou melhor score geral ({scores_a['final_score']:.1f}), indicando maior qualidade arquitetural.")
    elif scores_b['final_score'] > scores_a['final_score']:
        winner_name = name_b # Projeto Tradicional
        loser_name = name_a # Projeto DDD
        st.success(f"‚úÖ O **{winner_name}** apresentou melhor score geral ({scores_b['final_score']:.1f}), indicando maior qualidade arquitetural.")
    else:
        st.warning("‚öñÔ∏è Ambos os projetos tiveram scores equivalentes ‚Äî recomenda-se inspe√ß√£o qualitativa.")
    
    st.info("As m√©tricas visuais permitem compreender como o DDD influencia modularidade, acoplamento e manuten√ß√£o.")

    # === CONCLUS√ÉO GERAL (NOVO) ===
    # Esta se√ß√£o agora sabe qual projeto √© qual (name_a √© DDD, name_b √© Tradicional)
    st.subheader("üèÅ Conclus√£o Geral e Recomenda√ß√µes")
    
    ddd_context_text = ""
    
    if not winner_name:
        # Caso de empate
        ddd_context_text = "Ambos os projetos apresentaram scores finais equivalentes. Uma an√°lise qualitativa √© necess√°ria para determinar a melhor abordagem para o seu contexto de e-commerce."
    
    elif winner_name == name_a: # Se "Projeto DDD" venceu
        score_diff = abs(scores_a['final_score'] - scores_b['final_score'])
        ddd_context_text = f"""
        A an√°lise de m√©tricas quantitativas indicou que o **{name_a}** venceu, superando o **{name_b}** por **{score_diff:.1f}** pontos.
        
        **Contexto (DDD Venceu):**
        
        Os dados sugerem que a abordagem DDD foi **bem-sucedida** em criar uma arquitetura de maior qualidade, conforme as m√©tricas. Isso √© provavelmente vis√≠vel em:
        * **Menor Acoplamento:** Os m√≥dulos (Bounded Contexts) s√£o mais independentes.
        * **Maior n√∫mero de Dom√≠nios Detectados:** A separa√ß√£o de responsabilidades est√° mais clara.
        * **Maior √çndice de Manutenibilidade (MI):** O c√≥digo √© mais f√°cil de manter, apesar de talvez ser maior (mais LOC).
        
        **Recomenda√ß√£o:** O resultado quantitativo √© positivo. Aconselha-se agora focar na an√°lise qualitativa para garantir que a coes√£o e a clareza da "Linguagem Ubiqua" tamb√©m est√£o presentes.
        """
        
    elif winner_name == name_b: # Se "Projeto Tradicional" venceu
        score_diff = abs(scores_a['final_score'] - scores_b['final_score'])
        ddd_context_text = f"""
        A an√°lise de m√©tricas quantitativas indicou que o **{name_b}** venceu, superando o **{name_a}** por **{score_diff:.1f}** pontos.
        
        **Contexto (Tradicional Venceu):**
        
        Ver o projeto Tradicional vencer **n√£o √© necessariamente ruim**, mas levanta quest√µes importantes sobre a implementa√ß√£o do DDD:
        * O projeto DDD pode estar sofrendo de ***over-engineering*** (complexidade desnecess√°ria para o problema).
        * A implementa√ß√£o do DDD pode estar **falha**, resultando em alto acoplamento ou baixa coes√£o (ex: "Anemic Domain Model").
        * Alternativamente, a arquitetura tradicional pode ser simplesmente mais madura, simples e bem refatorada, sendo mais adequada para o escopo.
        
        **Recomenda√ß√£o:** Use esta an√°lise para investigar *por que* o projeto DDD teve um score menor. Verifique se o custo da complexidade do DDD est√° trazendo benef√≠cios qualitativos (clareza de neg√≥cio) que as m√©tricas n√£o capturam.
        """

    st.markdown(ddd_context_text) # Exibe o texto da conclus√£o
    
    # Adiciona a recomenda√ß√£o final
    st.markdown("""
    ---
    **Nota Final:** Use esta an√°lise como ponto de partida. O "melhor" projeto (especialmente em DDD) tamb√©m √© definido pela **coes√£o** (l√≥gica de neg√≥cio agrupada) e pela **clareza** com que o c√≥digo reflete a linguagem de neg√≥cio (Linguagem Ubiqua), m√©tricas que esta ferramenta n√£o mede qualitativamente.
    """)


    # Expander para debug e pesos
    with st.expander("üìÇ Ver dados JSON recebidos (Debug)"):
        st.json({"Projeto 1": metrics_a, "Projeto 2": metrics_b})
        st.json({"Scores (0-100) Projeto 1": scores_a, "Scores (0-100) Projeto 2": scores_b})
        st.json({"Pesos Aplicados (Normalizados)": weights})

def save_json_report(output_path, payload):
    p = Path(output_path)
    p.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as fh:
        json.dump(payload, fh, indent=2, ensure_ascii=False)
    return str(p)